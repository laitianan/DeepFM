import tensorrt as trt
import os

def convert_onnx_to_tensorrt(onnx_path, engine_path, fp16_mode=True, max_workspace_size=2048):
    """
    ä½¿ç”¨Python APIå°†ONNXæ¨¡å‹è½¬æ¢ä¸ºTensorRTå¼•æ“
    
    Args:
        onnx_path: ONNXæ¨¡å‹æ–‡ä»¶è·¯å¾„
        engine_path: è¾“å‡ºçš„TensorRTå¼•æ“è·¯å¾„
        fp16_mode: æ˜¯å¦å¯ç”¨FP16ç²¾åº¦
        max_workspace_size: æœ€å¤§å·¥ä½œç©ºé—´å¤§å°(MB)
    """
    # åˆ›å»ºæ—¥å¿—è®°å½•å™¨
    logger = trt.Logger(trt.Logger.WARNING)
    
    # åˆ›å»ºæ„å»ºå™¨
    builder = trt.Builder(logger)
    
    # åˆ›å»ºç½‘ç»œå®šä¹‰ï¼ˆå¿…é¡»å¯ç”¨EXPLICIT_BATCHä»¥æ”¯æŒåŠ¨æ€å½¢çŠ¶ï¼‰
    network = builder.create_network(1 << int(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH))
    
    # åˆ›å»ºONNXè§£æå™¨
    parser = trt.OnnxParser(network, logger)
    
    # åŠ è½½å¹¶è§£æONNXæ¨¡å‹
    with open(onnx_path, "rb") as model:
        if not parser.parse(model.read()):
            print("Failed to parse ONNX model")
            for error in range(parser.num_errors):
                print(parser.get_error(error))
            return False
    
    print("ONNXæ¨¡å‹è§£ææˆåŠŸï¼")
    
    # æ£€æŸ¥ç½‘ç»œè¾“å…¥ï¼Œç¡®å®šå®é™…çš„è¾“å…¥å¼ é‡åç§°å’Œå½¢çŠ¶
    print("ç½‘ç»œè¾“å…¥ä¿¡æ¯ï¼š")
    for i in range(network.num_inputs):
        input_tensor = network.get_input(i)
        print(f"è¾“å…¥ {i}: åç§°='{input_tensor.name}', å½¢çŠ¶={input_tensor.shape}")
    
    # åˆ›å»ºæ„å»ºé…ç½®
    config = builder.create_builder_config()
    
    # è®¾ç½®å·¥ä½œç©ºé—´å¤§å°
    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, max_workspace_size * (1 << 20))
    
    # åˆ›å»ºä¼˜åŒ–é…ç½®æ–‡ä»¶
    profile = builder.create_optimization_profile()
    
    # å…³é”®ä¿®æ”¹ï¼šæ ¹æ®å®é™…æ¨¡å‹è¾“å…¥é…ç½®åŠ¨æ€å½¢çŠ¶
    # å‡è®¾æ‚¨çš„FMæ¨¡å‹æœ‰ä¸¤ä¸ªè¾“å…¥ï¼šfeature_indiceså’Œfeature_values
    # éœ€è¦ä¸ºæ¯ä¸ªè¾“å…¥åˆ†åˆ«è®¾ç½®åŠ¨æ€å½¢çŠ¶èŒƒå›´
    
    # è·å–å®é™…çš„è¾“å…¥åç§°ï¼ˆè€Œä¸æ˜¯ç¡¬ç¼–ç ï¼‰
    input_names = [network.get_input(i).name for i in range(network.num_inputs)]
    print(f"æ£€æµ‹åˆ°çš„è¾“å…¥åç§°: {input_names}")
    
    # ä¸ºæ¯ä¸ªè¾“å…¥é…ç½®åŠ¨æ€å½¢çŠ¶èŒƒå›´
    for input_name in input_names:
        # è·å–è¾“å…¥çš„åŸå§‹å½¢çŠ¶ä¿¡æ¯
        input_tensor = None
        for i in range(network.num_inputs):
            if network.get_input(i).name == input_name:
                input_tensor = network.get_input(i)
                break
        
        if input_tensor is None:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°è¾“å…¥å¼ é‡ '{input_name}'")
            continue
            
        original_shape = input_tensor.shape
        print(f"é…ç½®è¾“å…¥ '{input_name}' çš„åŠ¨æ€å½¢çŠ¶ï¼ŒåŸå§‹å½¢çŠ¶: {original_shape}")
        
        # æ ¹æ®è¾“å…¥ç±»å‹è®¾ç½®ä¸åŒçš„åŠ¨æ€å½¢çŠ¶èŒƒå›´
        if "indices" in input_name.lower():
            # ç‰¹å¾ç´¢å¼•è¾“å…¥ï¼šé€šå¸¸æ˜¯æ•´æ•°ç±»å‹ï¼Œå½¢çŠ¶ä¸º [batch_size, sequence_length]
            min_shape = (1, 5)      # æœ€å°æ‰¹æ¬¡=1ï¼Œæœ€å°åºåˆ—é•¿åº¦=5
            opt_shape = (32, 10)    # æœ€ä¼˜æ‰¹æ¬¡=32ï¼Œæœ€ä¼˜åºåˆ—é•¿åº¦=10
            max_shape = (64, 500)   # æœ€å¤§æ‰¹æ¬¡=64ï¼Œæœ€å¤§åºåˆ—é•¿åº¦=500
        elif "values" in input_name.lower():
            # ç‰¹å¾å€¼è¾“å…¥ï¼šé€šå¸¸æ˜¯æµ®ç‚¹ç±»å‹ï¼Œå½¢çŠ¶ä¸indicesç›¸åŒ
            min_shape = (1, 5)      # ä¸indicesä¿æŒç›¸åŒçš„åŠ¨æ€ç»´åº¦
            opt_shape = (32, 10)
            max_shape = (64, 500)
        else:
            # é»˜è®¤é…ç½®ï¼ˆé€‚ç”¨äºå…¶ä»–è¾“å…¥ï¼‰
            min_shape = (1, 5)
            opt_shape = (32, 10)
            max_shape = (64, 500)
        
        # è®¾ç½®åŠ¨æ€å½¢çŠ¶èŒƒå›´
        profile.set_shape(input_name, min_shape, opt_shape, max_shape)
        print(f"  è®¾ç½®åŠ¨æ€å½¢çŠ¶: min={min_shape}, opt={opt_shape}, max={max_shape}")
    
    # å°†ä¼˜åŒ–é…ç½®æ–‡ä»¶æ·»åŠ åˆ°æ„å»ºé…ç½®ä¸­
    config.add_optimization_profile(profile)
    
    # å¯ç”¨FP16ç²¾åº¦ï¼ˆå¦‚æœæ”¯æŒï¼‰
    if fp16_mode and builder.platform_has_fast_fp16:
        config.set_flag(trt.BuilderFlag.FP16)
        print("å·²å¯ç”¨FP16ç²¾åº¦æ¨¡å¼")
    else:
        print("ä½¿ç”¨FP32ç²¾åº¦æ¨¡å¼")
    
    # æ„å»ºå¼•æ“
    print("å¼€å§‹æ„å»ºTensorRTå¼•æ“ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ...ï¼‰")
    serialized_engine = builder.build_serialized_network(network, config)
    
    if serialized_engine is None:
        print("Failed to build TensorRT engine")
        return False
    
    # ä¿å­˜å¼•æ“æ–‡ä»¶
    with open(engine_path, "wb") as f:
        f.write(serialized_engine)
    
    print(f"âœ… TensorRTå¼•æ“å·²æˆåŠŸä¿å­˜è‡³: {engine_path}")
    
    # è¾“å‡ºå¼•æ“ä¿¡æ¯
    runtime = trt.Runtime(logger)
    engine = runtime.deserialize_cuda_engine(serialized_engine)
    
    print("å¼•æ“æ„å»ºå®Œæˆï¼è¯¦ç»†ä¿¡æ¯ï¼š")
    print(f"  è¾“å…¥æ•°é‡: {engine.num_bindings}")
    for i in range(engine.num_bindings):
        name = engine.get_binding_name(i)
        dtype = engine.get_binding_dtype(i)
        shape = engine.get_binding_shape(i)
        is_input = engine.binding_is_input(i)
        print(f"  {'è¾“å…¥' if is_input else 'è¾“å‡º'} {i}: {name}, ç±»å‹={dtype}, å½¢çŠ¶={shape}")
    
    return True

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    success = convert_onnx_to_tensorrt("fm_model.onnx", "fm_model.engine", fp16_mode=True)
    if success:
        print("ğŸ‰ æ¨¡å‹è½¬æ¢æˆåŠŸï¼")
    else:
        print("âŒ æ¨¡å‹è½¬æ¢å¤±è´¥")